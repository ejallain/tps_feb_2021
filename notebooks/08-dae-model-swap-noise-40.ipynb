{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\eria\\Anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tps_feb_2021.config import config\n",
    "from tps_feb_2021.utils import add_noise, save_model, get_run_logdir, extract_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = config['data_dir']\n",
    "\n",
    "train_raw = pd.read_csv(data_dir + 'raw/train.csv')\n",
    "test_raw = pd.read_csv(data_dir + 'raw/test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_cols = [col for col in train_raw.columns if col[:4] == 'cont']\n",
    "cat_cols = [col for col in train_raw.columns if col[:3] == 'cat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat0</th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>cat4</th>\n",
       "      <th>cat5</th>\n",
       "      <th>cat6</th>\n",
       "      <th>cat7</th>\n",
       "      <th>cat8</th>\n",
       "      <th>cat9</th>\n",
       "      <th>...</th>\n",
       "      <th>cont4</th>\n",
       "      <th>cont5</th>\n",
       "      <th>cont6</th>\n",
       "      <th>cont7</th>\n",
       "      <th>cont8</th>\n",
       "      <th>cont9</th>\n",
       "      <th>cont10</th>\n",
       "      <th>cont11</th>\n",
       "      <th>cont12</th>\n",
       "      <th>cont13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>C</td>\n",
       "      <td>I</td>\n",
       "      <td>...</td>\n",
       "      <td>0.281421</td>\n",
       "      <td>0.881122</td>\n",
       "      <td>0.421650</td>\n",
       "      <td>0.741413</td>\n",
       "      <td>0.895799</td>\n",
       "      <td>0.802461</td>\n",
       "      <td>0.724417</td>\n",
       "      <td>0.701915</td>\n",
       "      <td>0.877618</td>\n",
       "      <td>0.719903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>A</td>\n",
       "      <td>F</td>\n",
       "      <td>...</td>\n",
       "      <td>0.282354</td>\n",
       "      <td>0.440011</td>\n",
       "      <td>0.346230</td>\n",
       "      <td>0.278495</td>\n",
       "      <td>0.593413</td>\n",
       "      <td>0.546056</td>\n",
       "      <td>0.613252</td>\n",
       "      <td>0.741289</td>\n",
       "      <td>0.326679</td>\n",
       "      <td>0.808464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>C</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>0.293756</td>\n",
       "      <td>0.914155</td>\n",
       "      <td>0.369602</td>\n",
       "      <td>0.832564</td>\n",
       "      <td>0.865620</td>\n",
       "      <td>0.825251</td>\n",
       "      <td>0.264104</td>\n",
       "      <td>0.695561</td>\n",
       "      <td>0.869133</td>\n",
       "      <td>0.828352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>G</td>\n",
       "      <td>K</td>\n",
       "      <td>...</td>\n",
       "      <td>0.769785</td>\n",
       "      <td>0.934138</td>\n",
       "      <td>0.578930</td>\n",
       "      <td>0.407313</td>\n",
       "      <td>0.868099</td>\n",
       "      <td>0.794402</td>\n",
       "      <td>0.494269</td>\n",
       "      <td>0.698125</td>\n",
       "      <td>0.809799</td>\n",
       "      <td>0.614766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>C</td>\n",
       "      <td>F</td>\n",
       "      <td>...</td>\n",
       "      <td>0.279105</td>\n",
       "      <td>0.382600</td>\n",
       "      <td>0.705940</td>\n",
       "      <td>0.325193</td>\n",
       "      <td>0.440967</td>\n",
       "      <td>0.462146</td>\n",
       "      <td>0.724447</td>\n",
       "      <td>0.683073</td>\n",
       "      <td>0.343457</td>\n",
       "      <td>0.297743</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  cat0 cat1 cat2 cat3 cat4 cat5 cat6 cat7 cat8 cat9  ...     cont4     cont5  \\\n",
       "0    A    B    A    A    B    D    A    E    C    I  ...  0.281421  0.881122   \n",
       "1    B    A    A    A    B    B    A    E    A    F  ...  0.282354  0.440011   \n",
       "2    A    A    A    C    B    D    A    B    C    N  ...  0.293756  0.914155   \n",
       "3    A    A    A    C    B    D    A    E    G    K  ...  0.769785  0.934138   \n",
       "4    A    B    A    A    B    B    A    E    C    F  ...  0.279105  0.382600   \n",
       "\n",
       "      cont6     cont7     cont8     cont9    cont10    cont11    cont12  \\\n",
       "0  0.421650  0.741413  0.895799  0.802461  0.724417  0.701915  0.877618   \n",
       "1  0.346230  0.278495  0.593413  0.546056  0.613252  0.741289  0.326679   \n",
       "2  0.369602  0.832564  0.865620  0.825251  0.264104  0.695561  0.869133   \n",
       "3  0.578930  0.407313  0.868099  0.794402  0.494269  0.698125  0.809799   \n",
       "4  0.705940  0.325193  0.440967  0.462146  0.724447  0.683073  0.343457   \n",
       "\n",
       "     cont13  \n",
       "0  0.719903  \n",
       "1  0.808464  \n",
       "2  0.828352  \n",
       "3  0.614766  \n",
       "4  0.297743  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.concat([train_raw[cat_cols + cont_cols], test_raw[cat_cols + cont_cols]])\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500000, 24)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_X = add_noise(X, p=0.40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "cont_X_scaled = pd.DataFrame(scaler.fit_transform(X[cont_cols]), columns=cont_cols)\n",
    "cont_noisy_X_scaled = pd.DataFrame(scaler.fit_transform(noisy_X[cont_cols]), columns=cont_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_one_hot_cats = pd.get_dummies(noisy_X[cat_cols])\n",
    "one_hot_cats = pd.get_dummies(X[cat_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_X = pd.concat([noisy_one_hot_cats, cont_noisy_X_scaled], axis=1)\n",
    "X = pd.concat([one_hot_cats.reset_index(drop=True), cont_X_scaled.reset_index(drop=True)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500000, 70)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noisy_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500000, 70)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['cat0_A', 'cat0_B', 'cat1_A', 'cat1_B', 'cat2_A', 'cat2_B', 'cat3_A',\n",
       "       'cat3_B', 'cat3_C', 'cat3_D', 'cat4_A', 'cat4_B', 'cat4_C', 'cat4_D',\n",
       "       'cat5_A', 'cat5_B', 'cat5_C', 'cat5_D', 'cat6_A', 'cat6_B', 'cat6_C',\n",
       "       'cat6_D', 'cat6_E', 'cat6_G', 'cat6_H', 'cat6_I', 'cat7_A', 'cat7_B',\n",
       "       'cat7_C', 'cat7_D', 'cat7_E', 'cat7_F', 'cat7_G', 'cat7_I', 'cat8_A',\n",
       "       'cat8_B', 'cat8_C', 'cat8_D', 'cat8_E', 'cat8_F', 'cat8_G', 'cat9_A',\n",
       "       'cat9_B', 'cat9_C', 'cat9_D', 'cat9_E', 'cat9_F', 'cat9_G', 'cat9_H',\n",
       "       'cat9_I', 'cat9_J', 'cat9_K', 'cat9_L', 'cat9_M', 'cat9_N', 'cat9_O',\n",
       "       'cont0', 'cont1', 'cont2', 'cont3', 'cont4', 'cont5', 'cont6', 'cont7',\n",
       "       'cont8', 'cont9', 'cont10', 'cont11', 'cont12', 'cont13'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noisy_X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['cat0_A', 'cat0_B', 'cat1_A', 'cat1_B', 'cat2_A', 'cat2_B', 'cat3_A',\n",
       "       'cat3_B', 'cat3_C', 'cat3_D', 'cat4_A', 'cat4_B', 'cat4_C', 'cat4_D',\n",
       "       'cat5_A', 'cat5_B', 'cat5_C', 'cat5_D', 'cat6_A', 'cat6_B', 'cat6_C',\n",
       "       'cat6_D', 'cat6_E', 'cat6_G', 'cat6_H', 'cat6_I', 'cat7_A', 'cat7_B',\n",
       "       'cat7_C', 'cat7_D', 'cat7_E', 'cat7_F', 'cat7_G', 'cat7_I', 'cat8_A',\n",
       "       'cat8_B', 'cat8_C', 'cat8_D', 'cat8_E', 'cat8_F', 'cat8_G', 'cat9_A',\n",
       "       'cat9_B', 'cat9_C', 'cat9_D', 'cat9_E', 'cat9_F', 'cat9_G', 'cat9_H',\n",
       "       'cat9_I', 'cat9_J', 'cat9_K', 'cat9_L', 'cat9_M', 'cat9_N', 'cat9_O',\n",
       "       'cont0', 'cont1', 'cont2', 'cont3', 'cont4', 'cont5', 'cont6', 'cont7',\n",
       "       'cont8', 'cont9', 'cont10', 'cont11', 'cont12', 'cont13'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Input(shape=noisy_X.shape[1:]),\n",
    "    keras.layers.Dense(500, activation='relu'),\n",
    "    keras.layers.Dense(500, activation='relu'),\n",
    "    keras.layers.Dense(500, activation='relu'),\n",
    "    keras.layers.Dense(70)\n",
    "])\n",
    "\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.Adam(learning_rate=0.001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_logdir = get_run_logdir()\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2001\n",
      "15625/15625 [==============================] - 110s 7ms/step - loss: 0.1375\n",
      "Epoch 2/2001\n",
      "15625/15625 [==============================] - 99s 6ms/step - loss: 0.1331\n",
      "Epoch 3/2001\n",
      "15625/15625 [==============================] - 98s 6ms/step - loss: 0.1318\n",
      "Epoch 4/2001\n",
      "15625/15625 [==============================] - 99s 6ms/step - loss: 0.1312\n",
      "Epoch 5/2001\n",
      "15625/15625 [==============================] - 98s 6ms/step - loss: 0.1309\n",
      "Epoch 6/2001\n",
      "15625/15625 [==============================] - 98s 6ms/step - loss: 0.1306\n",
      "Epoch 7/2001\n",
      "15625/15625 [==============================] - 98s 6ms/step - loss: 0.1304\n",
      "Epoch 8/2001\n",
      "15625/15625 [==============================] - 99s 6ms/step - loss: 0.1303\n",
      "Epoch 9/2001\n",
      "15625/15625 [==============================] - 105s 7ms/step - loss: 0.1301\n",
      "Epoch 10/2001\n",
      "15625/15625 [==============================] - 107s 7ms/step - loss: 0.1300\n",
      "Epoch 11/2001\n",
      "15625/15625 [==============================] - 103s 7ms/step - loss: 0.1299\n",
      "Epoch 12/2001\n",
      "15625/15625 [==============================] - 103s 7ms/step - loss: 0.1298\n",
      "Epoch 13/2001\n",
      "15625/15625 [==============================] - 103s 7ms/step - loss: 0.1297\n",
      "Epoch 14/2001\n",
      "15625/15625 [==============================] - 104s 7ms/step - loss: 0.1297\n",
      "Epoch 15/2001\n",
      "15625/15625 [==============================] - 105s 7ms/step - loss: 0.1296\n",
      "Epoch 16/2001\n",
      "15625/15625 [==============================] - 104s 7ms/step - loss: 0.1296\n",
      "Epoch 17/2001\n",
      "15625/15625 [==============================] - 105s 7ms/step - loss: 0.1295\n",
      "Epoch 18/2001\n",
      "15625/15625 [==============================] - 107s 7ms/step - loss: 0.1294\n",
      "Epoch 19/2001\n",
      "15625/15625 [==============================] - 106s 7ms/step - loss: 0.1294\n",
      "Epoch 20/2001\n",
      "15625/15625 [==============================] - 107s 7ms/step - loss: 0.1294\n",
      "Epoch 21/2001\n",
      "15625/15625 [==============================] - 106s 7ms/step - loss: 0.1293\n",
      "Epoch 22/2001\n",
      "15625/15625 [==============================] - 106s 7ms/step - loss: 0.1293\n",
      "Epoch 23/2001\n",
      "15625/15625 [==============================] - 106s 7ms/step - loss: 0.1293\n",
      "Epoch 24/2001\n",
      "15625/15625 [==============================] - 106s 7ms/step - loss: 0.1292\n",
      "Epoch 25/2001\n",
      "15625/15625 [==============================] - 107s 7ms/step - loss: 0.1292\n",
      "Epoch 26/2001\n",
      "15625/15625 [==============================] - 107s 7ms/step - loss: 0.1291\n",
      "Epoch 27/2001\n",
      "15625/15625 [==============================] - 110s 7ms/step - loss: 0.1291\n",
      "Epoch 28/2001\n",
      "15625/15625 [==============================] - 115s 7ms/step - loss: 0.1291\n",
      "Epoch 29/2001\n",
      "15625/15625 [==============================] - 113s 7ms/step - loss: 0.1290\n",
      "Epoch 30/2001\n",
      "15625/15625 [==============================] - 111s 7ms/step - loss: 0.1290\n",
      "Epoch 31/2001\n",
      "15625/15625 [==============================] - 108s 7ms/step - loss: 0.1290\n",
      "Epoch 32/2001\n",
      "15625/15625 [==============================] - 110s 7ms/step - loss: 0.1290\n",
      "Epoch 33/2001\n",
      "15625/15625 [==============================] - 111s 7ms/step - loss: 0.1289\n",
      "Epoch 34/2001\n",
      "15625/15625 [==============================] - 109s 7ms/step - loss: 0.1289\n",
      "Epoch 35/2001\n",
      "15625/15625 [==============================] - 110s 7ms/step - loss: 0.1289\n",
      "Epoch 36/2001\n",
      "15625/15625 [==============================] - 110s 7ms/step - loss: 0.1289\n",
      "Epoch 37/2001\n",
      "15625/15625 [==============================] - 111s 7ms/step - loss: 0.1288\n",
      "Epoch 38/2001\n",
      "15625/15625 [==============================] - 111s 7ms/step - loss: 0.1288\n",
      "Epoch 39/2001\n",
      "15625/15625 [==============================] - 112s 7ms/step - loss: 0.1288\n",
      "Epoch 40/2001\n",
      "15625/15625 [==============================] - 111s 7ms/step - loss: 0.1288\n",
      "Epoch 41/2001\n",
      "15625/15625 [==============================] - 113s 7ms/step - loss: 0.1288\n",
      "Epoch 42/2001\n",
      "15625/15625 [==============================] - 112s 7ms/step - loss: 0.1287\n",
      "Epoch 43/2001\n",
      "15625/15625 [==============================] - 115s 7ms/step - loss: 0.1288\n",
      "Epoch 44/2001\n",
      "15625/15625 [==============================] - 115s 7ms/step - loss: 0.1287\n",
      "Epoch 45/2001\n",
      "15625/15625 [==============================] - 116s 7ms/step - loss: 0.1287\n",
      "Epoch 46/2001\n",
      "15625/15625 [==============================] - 115s 7ms/step - loss: 0.1287\n",
      "Epoch 47/2001\n",
      "15625/15625 [==============================] - 117s 8ms/step - loss: 0.1287\n",
      "Epoch 48/2001\n",
      "15625/15625 [==============================] - 118s 8ms/step - loss: 0.1286\n",
      "Epoch 49/2001\n",
      "15625/15625 [==============================] - 117s 7ms/step - loss: 0.1286\n",
      "Epoch 50/2001\n",
      "15625/15625 [==============================] - 117s 7ms/step - loss: 0.1286\n",
      "Epoch 51/2001\n",
      "15625/15625 [==============================] - 118s 8ms/step - loss: 0.1286\n",
      "Epoch 52/2001\n",
      "15625/15625 [==============================] - 119s 8ms/step - loss: 0.1286\n",
      "Epoch 53/2001\n",
      "15625/15625 [==============================] - 118s 8ms/step - loss: 0.1286\n",
      "Epoch 54/2001\n",
      "15625/15625 [==============================] - 120s 8ms/step - loss: 0.1286\n",
      "Epoch 55/2001\n",
      "15625/15625 [==============================] - 120s 8ms/step - loss: 0.1286\n",
      "Epoch 56/2001\n",
      "15625/15625 [==============================] - 120s 8ms/step - loss: 0.1286\n",
      "Epoch 57/2001\n",
      "15625/15625 [==============================] - 120s 8ms/step - loss: 0.1285\n",
      "Epoch 58/2001\n",
      "15625/15625 [==============================] - 119s 8ms/step - loss: 0.1285\n",
      "Epoch 59/2001\n",
      "15625/15625 [==============================] - 122s 8ms/step - loss: 0.1285\n",
      "Epoch 60/2001\n",
      "15625/15625 [==============================] - 121s 8ms/step - loss: 0.1285\n",
      "Epoch 61/2001\n",
      "15625/15625 [==============================] - 122s 8ms/step - loss: 0.1285\n",
      "Epoch 62/2001\n",
      "15625/15625 [==============================] - 121s 8ms/step - loss: 0.1285\n",
      "Epoch 63/2001\n",
      "15625/15625 [==============================] - 122s 8ms/step - loss: 0.1285\n",
      "Epoch 64/2001\n",
      "15625/15625 [==============================] - 121s 8ms/step - loss: 0.1285\n",
      "Epoch 65/2001\n",
      "15625/15625 [==============================] - 122s 8ms/step - loss: 0.1285\n",
      "Epoch 66/2001\n",
      "15625/15625 [==============================] - 123s 8ms/step - loss: 0.1285\n",
      "Epoch 67/2001\n",
      "15625/15625 [==============================] - 123s 8ms/step - loss: 0.1285\n",
      "Epoch 68/2001\n",
      "15625/15625 [==============================] - 124s 8ms/step - loss: 0.1285\n",
      "Epoch 69/2001\n",
      "15625/15625 [==============================] - 124s 8ms/step - loss: 0.1285\n",
      "Epoch 70/2001\n",
      "15625/15625 [==============================] - 126s 8ms/step - loss: 0.1284\n",
      "Epoch 71/2001\n",
      "15625/15625 [==============================] - 126s 8ms/step - loss: 0.1284\n",
      "Epoch 72/2001\n",
      "15625/15625 [==============================] - 128s 8ms/step - loss: 0.1284\n",
      "Epoch 73/2001\n",
      "15625/15625 [==============================] - 130s 8ms/step - loss: 0.1284\n",
      "Epoch 74/2001\n",
      "15625/15625 [==============================] - 129s 8ms/step - loss: 0.1284\n",
      "Epoch 75/2001\n",
      "15625/15625 [==============================] - 130s 8ms/step - loss: 0.1284\n",
      "Epoch 76/2001\n",
      "15625/15625 [==============================] - 131s 8ms/step - loss: 0.1284\n",
      "Epoch 77/2001\n",
      "15625/15625 [==============================] - 133s 9ms/step - loss: 0.1284\n",
      "Epoch 78/2001\n",
      "15625/15625 [==============================] - 133s 9ms/step - loss: 0.1284\n",
      "Epoch 79/2001\n",
      "15625/15625 [==============================] - 156s 10ms/step - loss: 0.1284\n",
      "Epoch 80/2001\n",
      "15625/15625 [==============================] - 165s 11ms/step - loss: 0.1284\n",
      "Epoch 81/2001\n",
      "15625/15625 [==============================] - 165s 11ms/step - loss: 0.1284\n",
      "Epoch 82/2001\n",
      "15625/15625 [==============================] - 166s 11ms/step - loss: 0.1284\n",
      "Epoch 83/2001\n",
      "15625/15625 [==============================] - 167s 11ms/step - loss: 0.1283\n",
      "Epoch 84/2001\n",
      "15625/15625 [==============================] - 167s 11ms/step - loss: 0.1284\n",
      "Epoch 85/2001\n",
      "15625/15625 [==============================] - 168s 11ms/step - loss: 0.1283\n",
      "Epoch 86/2001\n",
      "15625/15625 [==============================] - 169s 11ms/step - loss: 0.1283\n",
      "Epoch 87/2001\n",
      "15625/15625 [==============================] - 170s 11ms/step - loss: 0.1283\n",
      "Epoch 88/2001\n",
      "15625/15625 [==============================] - 172s 11ms/step - loss: 0.1284\n",
      "Epoch 89/2001\n",
      "15625/15625 [==============================] - 172s 11ms/step - loss: 0.1283\n",
      "Epoch 90/2001\n",
      "15625/15625 [==============================] - 173s 11ms/step - loss: 0.1284\n",
      "Epoch 91/2001\n",
      "15625/15625 [==============================] - 173s 11ms/step - loss: 0.1283\n",
      "Epoch 92/2001\n",
      "15625/15625 [==============================] - 175s 11ms/step - loss: 0.1283\n",
      "Epoch 93/2001\n",
      "15625/15625 [==============================] - 175s 11ms/step - loss: 0.1283\n",
      "Epoch 94/2001\n",
      "15625/15625 [==============================] - 175s 11ms/step - loss: 0.1283\n",
      "Epoch 95/2001\n",
      "15625/15625 [==============================] - 176s 11ms/step - loss: 0.1283\n",
      "Epoch 96/2001\n",
      "15625/15625 [==============================] - 177s 11ms/step - loss: 0.1283\n",
      "Epoch 97/2001\n",
      "15625/15625 [==============================] - 177s 11ms/step - loss: 0.1283\n",
      "Epoch 98/2001\n",
      "15625/15625 [==============================] - 179s 11ms/step - loss: 0.1283\n",
      "Epoch 99/2001\n",
      "15625/15625 [==============================] - 180s 12ms/step - loss: 0.1283\n",
      "Epoch 100/2001\n",
      "15625/15625 [==============================] - 182s 12ms/step - loss: 0.1283\n",
      "Epoch 101/2001\n",
      "15625/15625 [==============================] - 183s 12ms/step - loss: 0.1283\n",
      "Epoch 102/2001\n",
      "15625/15625 [==============================] - 184s 12ms/step - loss: 0.1283\n",
      "Epoch 103/2001\n",
      "15625/15625 [==============================] - 185s 12ms/step - loss: 0.1283\n",
      "Epoch 104/2001\n",
      "15625/15625 [==============================] - 185s 12ms/step - loss: 0.1283\n",
      "Epoch 105/2001\n",
      "15625/15625 [==============================] - 187s 12ms/step - loss: 0.1283\n",
      "Epoch 106/2001\n",
      "15625/15625 [==============================] - 187s 12ms/step - loss: 0.1283\n",
      "Epoch 107/2001\n",
      "15625/15625 [==============================] - 193s 12ms/step - loss: 0.1283\n",
      "Epoch 108/2001\n",
      "15625/15625 [==============================] - 192s 12ms/step - loss: 0.1283\n",
      "Epoch 109/2001\n",
      "15625/15625 [==============================] - 189s 12ms/step - loss: 0.1283\n",
      "Epoch 110/2001\n",
      "15625/15625 [==============================] - 169s 11ms/step - loss: 0.1283\n",
      "Epoch 111/2001\n",
      "15625/15625 [==============================] - 160s 10ms/step - loss: 0.1283\n",
      "Epoch 112/2001\n",
      "15625/15625 [==============================] - 166s 11ms/step - loss: 0.1283\n",
      "Epoch 113/2001\n",
      "15625/15625 [==============================] - 162s 10ms/step - loss: 0.1283\n",
      "Epoch 114/2001\n",
      "15625/15625 [==============================] - 151s 10ms/step - loss: 0.1283\n",
      "Epoch 115/2001\n",
      "15625/15625 [==============================] - 149s 10ms/step - loss: 0.1283\n",
      "Epoch 116/2001\n",
      "15625/15625 [==============================] - 149s 10ms/step - loss: 0.1283\n",
      "Epoch 117/2001\n",
      "15625/15625 [==============================] - 168s 11ms/step - loss: 0.1283\n",
      "Epoch 118/2001\n",
      "15625/15625 [==============================] - 190s 12ms/step - loss: 0.1283\n",
      "Epoch 119/2001\n",
      "15625/15625 [==============================] - 181s 12ms/step - loss: 0.1283\n",
      "Epoch 120/2001\n",
      "15625/15625 [==============================] - 173s 11ms/step - loss: 0.1283\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(noisy_X, X, epochs=2001,\n",
    "                    callbacks=[tensorboard_cb, early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model, '06_dae_model_swap_noise_40.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = keras.models.load_model('../models/06_dae_model_swap_noise_25.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<KerasTensor: shape=(None, 70) dtype=float32 (created by layer 'input_1')>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15625/15625 [==============================] - 84s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "features_df = extract_features(model, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1490</th>\n",
       "      <th>1491</th>\n",
       "      <th>1492</th>\n",
       "      <th>1493</th>\n",
       "      <th>1494</th>\n",
       "      <th>1495</th>\n",
       "      <th>1496</th>\n",
       "      <th>1497</th>\n",
       "      <th>1498</th>\n",
       "      <th>1499</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.749727</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.301094</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.383269</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.382377</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.866042</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.600120</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.433342</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.074741</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.961982</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.710420</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.047975</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.804564</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.855798</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.092414</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.602676</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.962269</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.313632</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500000 rows × 1500 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0     1         2     3     4     5         6     7     8     9     \\\n",
       "0        0.0   0.0  0.000000   0.0   0.0   0.0  0.749727   0.0   0.0   0.0   \n",
       "1        0.0   0.0  0.000000   0.0   0.0   0.0  0.000000   0.0   0.0   0.0   \n",
       "2        0.0   0.0  0.000000   0.0   0.0   0.0  0.000000   0.0   0.0   0.0   \n",
       "3        0.0   0.0  0.000000   0.0   0.0   0.0  0.000000   0.0   0.0   0.0   \n",
       "4        0.0   0.0  0.000000   0.0   0.0   0.0  0.600120   0.0   0.0   0.0   \n",
       "...      ...   ...       ...   ...   ...   ...       ...   ...   ...   ...   \n",
       "499995   0.0   0.0  0.000000   0.0   0.0   0.0  0.961982   0.0   0.0   0.0   \n",
       "499996   0.0   0.0  1.047975   0.0   0.0   0.0  0.804564   0.0   0.0   0.0   \n",
       "499997   0.0   0.0  0.000000   0.0   0.0   0.0  0.092414   0.0   0.0   0.0   \n",
       "499998   0.0   0.0  0.000000   0.0   0.0   0.0  0.000000   0.0   0.0   0.0   \n",
       "499999   0.0   0.0  0.000000   0.0   0.0   0.0  0.000000   0.0   0.0   0.0   \n",
       "\n",
       "        ...  1490  1491  1492  1493      1494  1495      1496  1497      1498  \\\n",
       "0       ...   0.0   0.0   0.0   0.0  1.301094   0.0  1.383269   0.0  0.000000   \n",
       "1       ...   0.0   0.0   0.0   0.0  0.382377   0.0  0.000000   0.0  0.866042   \n",
       "2       ...   0.0   0.0   0.0   0.0  0.000000   0.0  0.000000   0.0  0.000000   \n",
       "3       ...   0.0   0.0   0.0   0.0  0.000000   0.0  0.000000   0.0  0.000000   \n",
       "4       ...   0.0   0.0   0.0   0.0  1.433342   0.0  0.000000   0.0  1.074741   \n",
       "...     ...   ...   ...   ...   ...       ...   ...       ...   ...       ...   \n",
       "499995  ...   0.0   0.0   0.0   0.0  0.000000   0.0  0.710420   0.0  0.000000   \n",
       "499996  ...   0.0   0.0   0.0   0.0  0.000000   0.0  0.000000   0.0  0.855798   \n",
       "499997  ...   0.0   0.0   0.0   0.0  0.000000   0.0  0.000000   0.0  0.000000   \n",
       "499998  ...   0.0   0.0   0.0   0.0  0.602676   0.0  0.000000   0.0  0.962269   \n",
       "499999  ...   0.0   0.0   0.0   0.0  0.000000   0.0  0.313632   0.0  0.000000   \n",
       "\n",
       "        1499  \n",
       "0        0.0  \n",
       "1        0.0  \n",
       "2        0.0  \n",
       "3        0.0  \n",
       "4        0.0  \n",
       "...      ...  \n",
       "499995   0.0  \n",
       "499996   0.0  \n",
       "499997   0.0  \n",
       "499998   0.0  \n",
       "499999   0.0  \n",
       "\n",
       "[500000 rows x 1500 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1490</th>\n",
       "      <th>1491</th>\n",
       "      <th>1492</th>\n",
       "      <th>1493</th>\n",
       "      <th>1494</th>\n",
       "      <th>1495</th>\n",
       "      <th>1496</th>\n",
       "      <th>1497</th>\n",
       "      <th>1498</th>\n",
       "      <th>1499</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>500000.000000</td>\n",
       "      <td>500000.000000</td>\n",
       "      <td>500000.000000</td>\n",
       "      <td>500000.000000</td>\n",
       "      <td>500000.0</td>\n",
       "      <td>500000.000000</td>\n",
       "      <td>500000.000000</td>\n",
       "      <td>500000.0</td>\n",
       "      <td>500000.000000</td>\n",
       "      <td>500000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>500000.000000</td>\n",
       "      <td>500000.000000</td>\n",
       "      <td>5.000000e+05</td>\n",
       "      <td>500000.0</td>\n",
       "      <td>500000.000000</td>\n",
       "      <td>500000.000000</td>\n",
       "      <td>500000.000000</td>\n",
       "      <td>500000.0</td>\n",
       "      <td>500000.000000</td>\n",
       "      <td>500000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.000475</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>0.351002</td>\n",
       "      <td>0.000972</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>0.661634</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000267</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>8.892937e-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.427041</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.210648</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.361074</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.023207</td>\n",
       "      <td>0.015219</td>\n",
       "      <td>0.584620</td>\n",
       "      <td>0.039583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014986</td>\n",
       "      <td>0.731846</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.018325</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005768</td>\n",
       "      <td>0.003460</td>\n",
       "      <td>6.288256e-04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.709982</td>\n",
       "      <td>0.012143</td>\n",
       "      <td>0.465592</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.479201</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.350689</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.572796</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.390294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.692814</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.956616</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.398247</td>\n",
       "      <td>3.077224</td>\n",
       "      <td>4.041704</td>\n",
       "      <td>4.753543</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.940678</td>\n",
       "      <td>3.236087</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.111079</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.090553</td>\n",
       "      <td>1.829194</td>\n",
       "      <td>4.446468e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.903209</td>\n",
       "      <td>2.788623</td>\n",
       "      <td>8.326519</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.172947</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 1500 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0              1              2              3         4     \\\n",
       "count  500000.000000  500000.000000  500000.000000  500000.000000  500000.0   \n",
       "mean        0.000475       0.000150       0.351002       0.000972       0.0   \n",
       "std         0.023207       0.015219       0.584620       0.039583       0.0   \n",
       "min         0.000000       0.000000       0.000000       0.000000       0.0   \n",
       "25%         0.000000       0.000000       0.000000       0.000000       0.0   \n",
       "50%         0.000000       0.000000       0.000000       0.000000       0.0   \n",
       "75%         0.000000       0.000000       0.572796       0.000000       0.0   \n",
       "max         3.398247       3.077224       4.041704       4.753543       0.0   \n",
       "\n",
       "                5              6         7              8         9     ...  \\\n",
       "count  500000.000000  500000.000000  500000.0  500000.000000  500000.0  ...   \n",
       "mean        0.000136       0.661634       0.0       0.000267       0.0  ...   \n",
       "std         0.014986       0.731846       0.0       0.018325       0.0  ...   \n",
       "min         0.000000       0.000000       0.0       0.000000       0.0  ...   \n",
       "25%         0.000000       0.000000       0.0       0.000000       0.0  ...   \n",
       "50%         0.000000       0.350689       0.0       0.000000       0.0  ...   \n",
       "75%         0.000000       1.390294       0.0       0.000000       0.0  ...   \n",
       "max         3.940678       3.236087       0.0       3.111079       0.0  ...   \n",
       "\n",
       "                1490           1491          1492      1493           1494  \\\n",
       "count  500000.000000  500000.000000  5.000000e+05  500000.0  500000.000000   \n",
       "mean        0.000020       0.000011  8.892937e-07       0.0       0.427041   \n",
       "std         0.005768       0.003460  6.288256e-04       0.0       0.709982   \n",
       "min         0.000000       0.000000  0.000000e+00       0.0       0.000000   \n",
       "25%         0.000000       0.000000  0.000000e+00       0.0       0.000000   \n",
       "50%         0.000000       0.000000  0.000000e+00       0.0       0.000000   \n",
       "75%         0.000000       0.000000  0.000000e+00       0.0       0.692814   \n",
       "max         3.090553       1.829194  4.446468e-01       0.0       6.903209   \n",
       "\n",
       "                1495           1496      1497           1498      1499  \n",
       "count  500000.000000  500000.000000  500000.0  500000.000000  500000.0  \n",
       "mean        0.000086       0.210648       0.0       0.361074       0.0  \n",
       "std         0.012143       0.465592       0.0       0.479201       0.0  \n",
       "min         0.000000       0.000000       0.0       0.000000       0.0  \n",
       "25%         0.000000       0.000000       0.0       0.000000       0.0  \n",
       "50%         0.000000       0.000000       0.0       0.000000       0.0  \n",
       "75%         0.000000       0.029857       0.0       0.956616       0.0  \n",
       "max         2.788623       8.326519       0.0       2.172947       0.0  \n",
       "\n",
       "[8 rows x 1500 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "descrip = features_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00014969886979088187"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descrip.loc['mean'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "active features =  715\n",
      "unused features =  785\n"
     ]
    }
   ],
   "source": [
    "unused_features = []\n",
    "active_features = []\n",
    "for col in features_df.columns:\n",
    "    if descrip.loc['mean'][col] == 0.0:\n",
    "        unused_features.append(col)\n",
    "    else:\n",
    "        active_features.append(col)\n",
    "print('active features = ', len(active_features))\n",
    "print('unused features = ', len(unused_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_features_df = features_df[active_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300000"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_features_df = active_features_df[:len(train_raw)]\n",
    "len(X_train_features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200000"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_features_df = active_features_df[len(train_raw):]\n",
    "len(X_test_features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_features_df.to_csv(data_dir + 'processed/X_train_dae_encoded_sn_40.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_features_df.to_csv(data_dir + 'processed/X_test_dae_encoded_sn_40.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test linear model fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.read_csv(data_dir + 'processed/y_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\eria\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=3.40513e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1, solver='cholesky')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_reg = Ridge(alpha=1, solver='cholesky')\n",
    "ridge_reg.fit(X_train_features_df, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = ridge_reg.predict(X_train_features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8563208600556839"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(y, y_pred, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2acbe491751959775267b317a38ea4b53e5da97b39b9edb9aff51f85edb8ae0a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
